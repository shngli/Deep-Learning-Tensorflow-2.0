{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "id": "se1ERqTk3gij",
    "outputId": "6160a25c-29de-432e-d65e-fa862b2ebf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
      "You set: `2.x  # Colab only.`. This will be interpreted as: `2.x`.\n",
      "\n",
      "\n",
      "TensorFlow 2.x selected.\n",
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow\n",
    "# !pip install -q tensorflow-gpu==2.0.0-beta1\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x  # Colab only.\n",
    "except Exception:\n",
    "  pass\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "To demonstrate how to do text preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJuj3OaF3kRu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dummy dataset with just three sentences. Next, we define a max vocab size = 20,000. This is usually a reasonable value. The Oxford Dictionary has almost 200,000 words, but the most common words in the English language number only about 3000, so 3000 will cover about 95% of most texts. So 20,000 is probably good enough. \n",
    "\n",
    "We instantiate the `Tokenizer()` class. Next we call `tokenizer.fit_on_texts()` and pass in our sentences list. \n",
    "Then we call `tokenizer.texts_to_sequences()` and pass in the same sentences list. This returns our sequences of integers. By the way, you can think of these two functions in terms of SKlearn feature transformer where you would always have a `fit()` and `transform()`. So the first one is like `fit()`, and the second one is like `transform()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvVTnycG4kpq"
   },
   "outputs": [],
   "source": [
    "# Just a simple test\n",
    "sentences = [\n",
    "    \"I like eggs and ham.\",\n",
    "    \"I love chocolate and bunnies.\",\n",
    "    \"I hate onions.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WIDEdlcb4Z5s"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 20000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to print out our sequences list. Normally on a text data set of any practical size, this would just print out way too much data. But since we only have three sentences, this is reasonable. We can see that each sentence has been converted into a list of integers, each integer corresponding to a word. Importantly, note that the integers start counting from 1 and not 0 as you might have expected. This is because Tensorflow uses 0 for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "fQZ9YQRC4wBq",
    "outputId": "b1919aa3-0333-42aa-ec35-6dfa8379b5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 2, 5], [1, 6, 7, 2, 8], [1, 9, 10]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be wondering how do I know which word corresponds to which integer? Luckily the tokenizer object already stores a dictionary with this information. Let's print out the tokenizer word index, and this is just like our word to index mapping. You should be able to look at this and confirm that if you map each integer back to the corresponding word, you should get back to the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "_68lEEPh5f3v",
    "outputId": "324a6039-7ec5-4a8b-b80d-eeb643e86a52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 2,\n",
       " 'bunnies': 8,\n",
       " 'chocolate': 7,\n",
       " 'eggs': 4,\n",
       " 'ham': 5,\n",
       " 'hate': 9,\n",
       " 'i': 1,\n",
       " 'like': 3,\n",
       " 'love': 6,\n",
       " 'onions': 10}"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to get the word to index mapping?\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out `pad_sequences()` with all the default values. While the default appears to set the maximum sequence length to be the maximum sentence length ie. 5, the first 2 sentences were already length 5 so there's no padding. For the third sentence, padding was added at the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "pbaSQMFO5dBA",
    "outputId": "676f0998-6362-4801-8327-db8d5cff11c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  2  5]\n",
      " [ 1  6  7  2  8]\n",
      " [ 0  0  1  9 10]]\n"
     ]
    }
   ],
   "source": [
    "# use the defaults\n",
    "data = pad_sequences(sequences)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that if we explicitly pass in max sequence length = 5, we get the same answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "8YWCY-SF9Wst",
    "outputId": "0635c0d2-11b6-4e89-f668-021bea0b575f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  2  5]\n",
      " [ 1  6  7  2  8]\n",
      " [ 0  0  1  9 10]]\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 5\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we set padding to `post`. We can see that the first two sentences still have no padding because they are of the maximum length. The third sentence now has 0s at the end instead of at the beginning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "C6b7hSXknAY1",
    "outputId": "07302ec4-b45f-4cc9-96e1-4ca018917916"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  2  5]\n",
      " [ 1  6  7  2  8]\n",
      " [ 1  9 10  0  0]]\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we add too much padding, so let's set padding = 6, which is longer than all of the sentences in our dataset. The first two sentences have been padded with one 0 so that the sequence length is 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "7-cx1YkzmxJn",
    "outputId": "fc3f51dd-3d3c-4aa4-a3d4-57613c2088ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  3  4  2  5]\n",
      " [ 0  1  6  7  2  8]\n",
      " [ 0  0  0  1  9 10]]\n"
     ]
    }
   ],
   "source": [
    "# too much padding\n",
    "data = pad_sequences(sequences, maxlen=6)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we set max length equal to a number less than the maximum sequence length. So let's try 4. In this case we can see that each sequence has been truncated to cut off the beginning of the sequences. This makes sense as the default because an RNN typically pays more attention to the final values in a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "rao9bGBWm2yl",
    "outputId": "f842473a-fdbd-457f-e197-4b4404239334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  4  2  5]\n",
      " [ 6  7  2  8]\n",
      " [ 0  1  9 10]]\n"
     ]
    }
   ],
   "source": [
    "# truncation\n",
    "data = pad_sequences(sequences, maxlen=4)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we set max length = 4 again, but this time we're going to set the truncating argument to `post`. In this case, we can see that the ends of the sequences have been cut off instead of the beginnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "31eDMQixm5rV",
    "outputId": "5e4ff536-4999-42f7-ae66-4a3cd8bc3b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4  2]\n",
      " [ 1  6  7  2]\n",
      " [ 0  1  9 10]]\n"
     ]
    }
   ],
   "source": [
    "data = pad_sequences(sequences, maxlen=4, truncating='post')\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
